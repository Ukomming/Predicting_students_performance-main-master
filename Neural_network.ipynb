{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96835a39-ec1b-4436-9251-1185cdb65161",
   "metadata": {},
   "source": [
    "#### Objective of this kernel:\n",
    "* To implement svm machine learning algorithm\n",
    "* To save our model \n",
    "* To  measure the accuracy of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd514da-25fe-4904-a463-e7257ecf41e6",
   "metadata": {},
   "source": [
    "## Importing our libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "26946232-00fc-4a9a-8267-f05f9d24592a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./output/linearmodel.pickle\n",
      "./output/naive_bayes.pickle\n",
      "./output/KNNmodel.pickle\n",
      "./output/processed_data.csv\n",
      "./output/cleaned_data.csv\n",
      "./output/Logregmodel.pickle\n",
      "./output/SVMmodel.pickle\n",
      "./output/.ipynb_checkpoints/cleaned_data-checkpoint.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Input data files are available in the \"../output/\" directory.\n",
    "import os\n",
    "\n",
    "for dirname, _, filenames in os.walk('./output/'):\n",
    "    \n",
    "    for filename in filenames:\n",
    "        \n",
    "        print(os.path.join(dirname, filename))\n",
    "        \n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd6be4e-7563-4e01-a548-75fcffd4e23b",
   "metadata": {},
   "source": [
    "## Reading the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "94ad51bd-6fcf-4e39-8c4b-a1913fcbd4d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(238, 8)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./output/cleaned_data.csv')\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daf1190-1840-46b1-8d20-7b5f796dae97",
   "metadata": {},
   "source": [
    "## we are going to transform all our categorical data to proper format to be fed to our machine learning algorithms\n",
    "* We preprocess our data with the LabelEncoder from sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27267582-7410-421e-8a7c-64b84185308b",
   "metadata": {},
   "source": [
    "#### Preprocessing our independent variable x and dependent variable y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fbe295a5-6fd1-4728-a330-e9777b687ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder_x=LabelEncoder()\n",
    "\n",
    "#preprocessing x\n",
    "\n",
    "Age=label_encoder_x.fit_transform(list(df[\"Age\"]))\n",
    "\n",
    "Gender=label_encoder_x.fit_transform(list(df[\"Gender\"]))\n",
    "\n",
    "wassce_grade=label_encoder_x.fit_transform(list(df[\"wassce grade\"]))\n",
    "\n",
    "level=label_encoder_x.fit_transform(list(df[\"level\"]))\n",
    "\n",
    "access_to_a_laptop_or_internet=label_encoder_x.fit_transform(list(df[\"access to a laptop or internet\"]))\n",
    "\n",
    "study_group=label_encoder_x.fit_transform(list(df[\"study group\"]))\n",
    "\n",
    "time_spent_on_independent_studies=label_encoder_x.fit_transform(list(df[\"time spent on independent studies\"]))\n",
    "\n",
    "current_CGPA=label_encoder_x.fit_transform(list(df[\"current CGPA\"]))\n",
    "\n",
    "\n",
    "x=list(zip(Age,Gender,wassce_grade,access_to_a_laptop_or_internet,study_group,time_spent_on_independent_studies,))\n",
    "y=list(current_CGPA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b3c660-3a20-4d8d-8184-f53ef24ce2b4",
   "metadata": {},
   "source": [
    "# Lets start implementing svm machine learning algorithm on our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b090a07e-f39b-47df-a1d1-03cf44c9ebed",
   "metadata": {},
   "source": [
    "### Fitting the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fd361b-3658-4637-ad67-cfc1df463df5",
   "metadata": {},
   "source": [
    "# scale dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f95b267a-ad54-4577-883e-2567094a4ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "import pickle # This is used to save our model to be used in the future\n",
    "\n",
    "# we split our data into training and testing dataset\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler # to scale our data \n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)\n",
    "from sklearn.preprocessing import StandardScaler # to scale our data \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b74307-f9b8-4dd9-8907-71e78ef3f1f7",
   "metadata": {},
   "source": [
    "### Initializing Support Neural Network and fitting the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8ba0b3f0-6ccc-41ef-8ebd-c8a888463080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'activation': 'logistic', 'hidden_layer_sizes': (1,), 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import sklearn\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "\n",
    "# Import necessary modules\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "        {\n",
    "            'activation' : ['identity', 'logistic', 'tanh', 'relu'],\n",
    "            'solver' : ['lbfgs', 'sgd', 'adam'],\n",
    "            'hidden_layer_sizes': [\n",
    "             (1,),(2,),(3,),(4,),(5,),(6,),(7,),(8,),(9,),(10,),(11,), (12,),(13,),(14,),(15,),(16,),(17,),(18,),(19,),(20,),(21,)\n",
    "             ]\n",
    "        }\n",
    "       ]\n",
    "best = 0\n",
    "mlp = MLPClassifier( max_iter=9900)\n",
    "\n",
    "clf = GridSearchCV(mlp, param_grid, cv=2,scoring='accuracy')\n",
    "clf.fit(x_train,y_train)\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(clf.best_params_)\n",
    "mlp.fit(x_train,y_train)\n",
    "nural_score = mlp.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "945ac535-f36e-4b87-9f3d-840cff935a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3541666666666667\n"
     ]
    }
   ],
   "source": [
    "with open(\"./output/Nural_network.pickle\",\"wb\") as f:\n",
    "            pickle.dump(mlp,f)\n",
    "print(nural_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d81a93d-0a9a-4a52-8667-d03315b0c797",
   "metadata": {},
   "source": [
    "### Predicting the classes for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "82c2ef91-017b-4171-aed2-b20048d0c228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Value: [2 2 1 2 2 3 2 3 1 3 4 4 2 2 2 2 3 3 2 3 1 3 2 1 3 1 4 3 3 2 2 2 2 3 2 2 3\n",
      " 2 4 3 4 1 4 2 1 3 2 3]\n"
     ]
    }
   ],
   "source": [
    "y_pred = mlp.predict(x_test)\n",
    "print (\"Predicted Value:\", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "939ca6f6-6003-4c93-bca4-fd534dcab138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Neural network: 35.42%\n",
      "\n",
      "Confusion of theNeural network:\n",
      "\n",
      "[[1 4 2 0]\n",
      " [4 7 2 2]\n",
      " [2 6 7 2]\n",
      " [0 3 4 2]]\n",
      "\n",
      "Classification Report of the Neural network:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.14      0.14      0.14         7\n",
      "           2       0.35      0.47      0.40        15\n",
      "           3       0.47      0.41      0.44        17\n",
      "           4       0.33      0.22      0.27         9\n",
      "\n",
      "    accuracy                           0.35        48\n",
      "   macro avg       0.32      0.31      0.31        48\n",
      "weighted avg       0.36      0.35      0.35        48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix,classification_report\n",
    "print(\"Accuracy of the Neural network: {}%\".format(round(accuracy_score(y_test, y_pred)*100,2)))\n",
    "print(\"\\nConfusion of theNeural network:\\n\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report of the Neural network:\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "55d4e2e1-1f2e-4911-9eab-6290d1dd33b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean_squared_error of the KNN is: 1.2083333333333333\n",
      "mean_squared_log_error of the KNN is: 0.11463724670286697\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error,mean_squared_log_error,confusion_matrix\n",
    "print(\"The mean_squared_error of the KNN is: {}\".format(mean_squared_error(y_test, y_pred)))\n",
    "print(\"mean_squared_log_error of the KNN is: {}\".format(mean_squared_log_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8654add-49c7-4d30-ac49-c6191de15931",
   "metadata": {},
   "source": [
    "#### loading linear KNN model so we dont have to rerun our algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2060267b-2a5d-4be9-a5a4-57b2f5d9053f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"./output/Nural_network.pickle\",\"rb\")\n",
    "regressor = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ca8525-86c5-440d-a0f2-03d1d29ce57f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
